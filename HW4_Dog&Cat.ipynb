{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CCGuCaTUhany-4zEgWeiI6kPXlGRc4b2",
      "authorship_tag": "ABX9TyOftW2qC6xemi348Nkcz6O/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imrib/ImriBregman-HW/blob/main/HW4_Dog%26Cat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification between dogs and cats using Keras and python\n",
        "The resolution of the pictures won't be fixed\n",
        "3 million pictures, we're going to use around 3k pictures\n",
        "(Coco is a dataset with a lot of pictures, that people annotated)\n",
        "\n",
        "1k training dog\n",
        "1k training cat\n",
        "1k validation set\n",
        "\n",
        "Research question: Dog or Cat?\n",
        "we don't need the color picture to differentiate between dogs and cats\n",
        "Resize the picture using keras function to 150x150, Flatten the picture (150,150,1) normalize the data also\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, 3, padding=’same’, activation=’relu’, input_shape=(150,150,3)\n",
        "\n",
        " in the end it also shows the confusion matrix of the train and test\n",
        "show the accuracy during the training at the end of each epoch"
      ],
      "metadata": {
        "id": "H26C9urb_Wuf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_-ETnY4-1ds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c26d079-73a0-4c2c-ff27-6eda0a6507a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "58/62 [===========================>..] - ETA: 17s - loss: 1.0453 - accuracy: 0.5435"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define paths\n",
        "base_dir = \"/content/drive/MyDrive/cats_and_dogs_filtered\"  # Update with your dataset path\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "validation_dir = os.path.join(base_dir, \"validation\")\n",
        "\n",
        "# Data preparation\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    color_mode='grayscale'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    color_mode='grayscale'\n",
        ")\n",
        "\n",
        "# Model definition\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=(150, 150, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Model training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size\n",
        ")\n",
        "\n",
        "# Model evaluation\n",
        "validation_generator.reset()\n",
        "pred_prob = model.predict(validation_generator)\n",
        "predictions = np.round(pred_prob)\n",
        "\n",
        "# Confusion matrix\n",
        "conf_mat = confusion_matrix(validation_generator.classes, predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_mat)\n",
        "\n",
        "# Plot accuracy during training\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ]
    }
  ]
}